{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799859ff",
   "metadata": {},
   "source": [
    "\n",
    "<a id='eigen'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2862739a",
   "metadata": {},
   "source": [
    "# 特征值和特征向量\n",
    "\n",
    "\n",
    "<a id='index-0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc4cc5",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "特征值和特征向量是线性代数中一个相对高级的话题。\n",
    "\n",
    "同时，这些概念在以下领域非常有用：\n",
    "\n",
    "- 经济建模（尤其是动态模型！）  \n",
    "- 统计学  \n",
    "- 应用数学的某些部分  \n",
    "- 机器学习  \n",
    "- 以及许多其他科学领域  \n",
    "\n",
    "\n",
    "在本讲座中，我们将解释特征值和特征向量的基础知识，并介绍诺伊曼级数引理。\n",
    "\n",
    "我们假设学生已经熟悉矩阵，并理解[矩阵代数的基础知识](https://quantecon.github.io/lecture-intro.zh-cn/linear_equations.html)。\n",
    "\n",
    "我们将使用以下导入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2a72a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import matrix_power\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba716d7a",
   "metadata": {},
   "source": [
    "\n",
    "<a id='matrices-as-transformation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992d6d3",
   "metadata": {},
   "source": [
    "## 矩阵作为变换\n",
    "\n",
    "让我们从讨论一个关于矩阵的重要概念开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45838dce",
   "metadata": {},
   "source": [
    "### 将向量映射到向量\n",
    "\n",
    "有两种思考矩阵的方式：\n",
    "\n",
    "1. 将矩阵视为一个矩形的数字集合。  \n",
    "1. 将矩阵视为一个将向量转换为新向量的*映射*（即函数）。  \n",
    "\n",
    "\n",
    "为了理解第二种观点，假设我们将一个 $ n \\times m $ 矩阵 $ A $ 与一个 $ m \\times 1 $ 列向量 $ x $ 相乘，得到一个 $ n \\times 1 $ 列向量 $ y $：\n",
    "\n",
    "$$\n",
    "Ax = y\n",
    "$$\n",
    "\n",
    "如果我们固定 $ A $ 并考虑不同的 $ x $，我们可以将 $ A $ 理解为一个将 $ x $ 转换为 $ Ax $ 的映射。\n",
    "\n",
    "因为 $ A $ 是 $ n \\times m $ 的，所以它将 $ m $ 维向量转换为 $ n $ 维向量。\n",
    "\n",
    "我们可以正式地将此写作 $ A \\colon \\mathbb{R}^m \\rightarrow \\mathbb{R}^n $。\n",
    "\n",
    "你可能会说，如果 $ A $ 是一个函数，那么我们应该写成 $ A(x) = y $ 而不是 $ Ax = y $，但后者的表示方法更为常见。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142fc010",
   "metadata": {},
   "source": [
    "### 方阵\n",
    "\n",
    "让我们将讨论限制在方阵上。\n",
    "\n",
    "在上述讨论中，这意味着 $ m=n $，则 $ A $ 将 $ \\mathbb R^n $ 映射到自身。\n",
    "\n",
    "这表示 $ A $ 是一个 $ n \\times n $ 矩阵，它将 $ \\mathbb{R}^n $ 中的向量 $ x $ 映射（或”变换”）为同样在 $ \\mathbb{R}^n $ 中的新向量 $ y=Ax $。\n",
    "\n",
    "以下是一个例子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663c2a0",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "        2 & 1 \\\\\n",
    "        -1 & 1\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        3\n",
    "    \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "        5 \\\\\n",
    "        2\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "在这里，矩阵\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 2 & 1 \\\\ \n",
    "                        -1 & 1 \n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "将向量 $ x = \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix} $ 变换为向量 $ y = \\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix} $。\n",
    "\n",
    "让我们用 Python 来可视化这个过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0fb872",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[2,  1],\n",
    "              [-1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9400b07f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# 设置坐标轴通过原点\n",
    "\n",
    "for spine in ['left', 'bottom']:\n",
    "    ax.spines[spine].set_position('zero')\n",
    "for spine in ['right', 'top']:\n",
    "    ax.spines[spine].set_color('none')\n",
    "\n",
    "ax.set(xlim=(-2, 6), ylim=(-2, 4), aspect=1)\n",
    "\n",
    "vecs = ((1, 3), (5, 2))\n",
    "c = ['r', 'black']\n",
    "for i, v in enumerate(vecs):\n",
    "    ax.annotate('', xy=v, xytext=(0, 0),\n",
    "                arrowprops=dict(color=c[i],\n",
    "                shrink=0,\n",
    "                alpha=0.7,\n",
    "                width=0.5))\n",
    "\n",
    "ax.text(0.2 + 1, 0.2 + 3, 'x=$(1,3)$')\n",
    "ax.text(0.2 + 5, 0.2 + 2, 'Ax=$(5,2)$')\n",
    "\n",
    "ax.annotate('', xy=(sqrt(10/29) * 5, sqrt(10/29) * 2), xytext=(0, 0),\n",
    "            arrowprops=dict(color='purple',\n",
    "                            shrink=0,\n",
    "                            alpha=0.7,\n",
    "                            width=0.5))\n",
    "\n",
    "ax.annotate('', xy=(1, 2/5), xytext=(1/3, 1),\n",
    "            arrowprops={'arrowstyle': '->',\n",
    "                        'connectionstyle': 'arc3,rad=-0.3'},\n",
    "            horizontalalignment='center')\n",
    "ax.text(0.8, 0.8, f'θ', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215e622",
   "metadata": {},
   "source": [
    "我们可以这样理解 $ A $：\n",
    "\n",
    "- 首先将 $ x $ 旋转某个角度 $ \\theta $，然后  \n",
    "- 将其缩放某个标量 $ \\gamma $ 以获得 $ x $ 的像 $ y $。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5949a62",
   "metadata": {},
   "source": [
    "## 变换类型\n",
    "\n",
    "让我们来检查一些可以用矩阵执行的标准变换。\n",
    "\n",
    "下面我们通过将向量视为点而不是箭头来可视化变换。\n",
    "\n",
    "我们将给定一个矩阵并观察它如何变换\n",
    "\n",
    "- 一个点阵网格和  \n",
    "- 位于 $ \\mathbb{R}^2 $ 中单位圆上的一组点。  \n",
    "\n",
    "\n",
    "为了构建这些变换，我们将使用两个函数，称为 `grid_transform` 和 `circle_transform`。\n",
    "\n",
    "这些函数中的每一个都可视化一个特定的 $ 2 \\times 2 $ 矩阵 $ A $ 的作用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db7479",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def colorizer(x, y):\n",
    "    r = min(1, 1-y/3)\n",
    "    g = min(1, 1+y/3)\n",
    "    b = 1/4 + x/16\n",
    "    return (r, g, b)\n",
    "\n",
    "\n",
    "def grid_transform(A=np.array([[1, -1], [1, 1]])):\n",
    "    xvals = np.linspace(-4, 4, 9)\n",
    "    yvals = np.linspace(-3, 3, 7)\n",
    "    xygrid = np.column_stack([[x, y] for x in xvals for y in yvals])\n",
    "    uvgrid = A @ xygrid\n",
    "\n",
    "    colors = list(map(colorizer, xygrid[0], xygrid[1]))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    for axes in ax:\n",
    "        axes.set(xlim=(-11, 11), ylim=(-11, 11))\n",
    "        axes.set_xticks([])\n",
    "        axes.set_yticks([])\n",
    "        for spine in ['left', 'bottom']:\n",
    "            axes.spines[spine].set_position('zero')\n",
    "        for spine in ['right', 'top']:\n",
    "            axes.spines[spine].set_color('none')\n",
    "\n",
    "    # 绘制x-y格点\n",
    "    ax[0].scatter(xygrid[0], xygrid[1], s=36, c=colors, edgecolor=\"none\")\n",
    "    # ax[0].grid(True)\n",
    "    # ax[0].axis(\"equal\")\n",
    "    ax[0].set_title(r\"点 $x_1, x_2, \\cdots, x_k$\")\n",
    "\n",
    "    # 绘制变换的格点\n",
    "    ax[1].scatter(uvgrid[0], uvgrid[1], s=36, c=colors, edgecolor=\"none\")\n",
    "    # ax[1].grid(True)\n",
    "    # ax[1].axis(\"equal\")\n",
    "    ax[1].set_title(r\"点 $Ax_1, Ax_2, \\cdots, Ax_k$\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def circle_transform(A=np.array([[-1, 2], [0, 1]])):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    for axes in ax:\n",
    "        axes.set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "        axes.set_xticks([])\n",
    "        axes.set_yticks([])\n",
    "        for spine in ['left', 'bottom']:\n",
    "            axes.spines[spine].set_position('zero')\n",
    "        for spine in ['right', 'top']:\n",
    "            axes.spines[spine].set_color('none')\n",
    "\n",
    "    θ = np.linspace(0, 2 * np.pi, 150)\n",
    "    r = 1\n",
    "\n",
    "    θ_1 = np.empty(12)\n",
    "    for i in range(12):\n",
    "        θ_1[i] = 2 * np.pi * (i/12)\n",
    "\n",
    "    x = r * np.cos(θ)\n",
    "    y = r * np.sin(θ)\n",
    "    a = r * np.cos(θ_1)\n",
    "    b = r * np.sin(θ_1)\n",
    "    a_1 = a.reshape(1, -1)\n",
    "    b_1 = b.reshape(1, -1)\n",
    "    colors = list(map(colorizer, a, b))\n",
    "    ax[0].plot(x, y, color='black', zorder=1)\n",
    "    ax[0].scatter(a_1, b_1, c=colors, alpha=1, s=60,\n",
    "                  edgecolors='black', zorder=2)\n",
    "    ax[0].set_title(r\"在 $\\mathbb{R}^2$的单位圆\")\n",
    "\n",
    "    x1 = x.reshape(1, -1)\n",
    "    y1 = y.reshape(1, -1)\n",
    "    ab = np.concatenate((a_1, b_1), axis=0)\n",
    "    transformed_ab = A @ ab\n",
    "    transformed_circle_input = np.concatenate((x1, y1), axis=0)\n",
    "    transformed_circle = A @ transformed_circle_input\n",
    "    ax[1].plot(transformed_circle[0, :],\n",
    "               transformed_circle[1, :], color='black', zorder=1)\n",
    "    ax[1].scatter(transformed_ab[0, :], transformed_ab[1:,],\n",
    "                  color=colors, alpha=1, s=60, edgecolors='black', zorder=2)\n",
    "    ax[1].set_title(\"变换后的圆\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb4657",
   "metadata": {},
   "source": [
    "### 缩放\n",
    "\n",
    "类似\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "        \\alpha & 0 \n",
    "        \\\\ 0 & \\beta \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "的矩阵沿 x 轴将向量缩放 $ \\alpha $ 倍，沿 y 轴缩放 $ \\beta $ 倍。\n",
    "\n",
    "这里我们举一个简单的例子，其中 $ \\alpha = \\beta = 3 $ 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dcbfa8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[3, 0],  # 在两个方向放大三倍\n",
    "              [0, 3]])\n",
    "grid_transform(A)\n",
    "circle_transform(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5a27d",
   "metadata": {},
   "source": [
    "### 剪切\n",
    "\n",
    "类似\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "        1 & \\lambda \\\\ \n",
    "        0 & 1 \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "的”剪切”矩阵沿 x 轴拉伸向量，拉伸量与点的 y 坐标成比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eda105",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2],     # 沿x-轴进行剪切\n",
    "              [0, 1]])\n",
    "grid_transform(A)\n",
    "circle_transform(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a03382",
   "metadata": {},
   "source": [
    "### 旋转\n",
    "\n",
    "类似\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "        \\cos \\theta & \\sin \\theta \n",
    "        \\\\ - \\sin \\theta & \\cos \\theta \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "的矩阵被称为 *旋转矩阵* 。\n",
    "\n",
    "这个矩阵将向量顺时针旋转角度 $ \\theta $ 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d002702",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "θ = np.pi/4  # 顺时针旋转45度\n",
    "A = np.array([[np.cos(θ), np.sin(θ)],\n",
    "              [-np.sin(θ), np.cos(θ)]])\n",
    "grid_transform(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1c4f0",
   "metadata": {},
   "source": [
    "### 置换\n",
    "\n",
    "置换矩阵\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "        0 & 1 \\\\ \n",
    "        1 & 0 \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "交换向量的坐标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9851f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.column_stack([[0, 1], [1, 0]])\n",
    "grid_transform(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e08b9b7",
   "metadata": {},
   "source": [
    "更多常见的变换矩阵示例可以在[这里](https://baike.baidu.com/item/%E5%8F%98%E6%8D%A2%E7%9F%A9%E9%98%B5/9035701)找到。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e13b6",
   "metadata": {},
   "source": [
    "## 矩阵乘法作为组合\n",
    "\n",
    "由于矩阵可以理解为将一个向量转换为另一个向量的函数，我们也可以将函数组合的概念应用于矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7722e",
   "metadata": {},
   "source": [
    "### 线性组合\n",
    "\n",
    "考虑两个矩阵\n",
    "\n",
    "$$\n",
    "A = \n",
    "        \\begin{bmatrix} \n",
    "            0 & 1 \\\\ \n",
    "            -1 & 0 \n",
    "        \\end{bmatrix}\n",
    "        \\quad \\text{和} \\quad\n",
    "    B = \n",
    "        \\begin{bmatrix} \n",
    "            1 & 2 \\\\ \n",
    "            0 & 1 \n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "当我们尝试对某个 $ 2 \\times 1 $ 向量 $ x $ 求 $ ABx $ 时，输出会是什么？\n",
    "\n",
    "$$\n",
    "\\color{red}{\\underbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  0 & 1 \\\\\n",
    " -1 & 0\n",
    " \\end{bmatrix}}\n",
    "}_{\\textstyle A} }\n",
    "\\color{red}{\\underbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  0 & 1\n",
    " \\end{bmatrix}}\n",
    "}_{\\textstyle B}}\n",
    "\\color{red}{\\overbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  1 \\\\\n",
    "  3\n",
    " \\end{bmatrix}}\n",
    "}^{\\textstyle x}}\n",
    "\\rightarrow\n",
    "\\color{red}{\\underbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  0 & 1 \\\\\n",
    "  -1 & -2\n",
    " \\end{bmatrix}}\n",
    "}_{\\textstyle AB}}\n",
    "\\color{red}{\\overbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  1 \\\\\n",
    "  3\n",
    " \\end{bmatrix}}\n",
    "}^{\\textstyle x}}\n",
    "\\rightarrow\n",
    "\\color{red}{\\overbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  3 \\\\\n",
    "  -7\n",
    " \\end{bmatrix}}\n",
    "}^{\\textstyle y}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\color{red}{\\underbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  0 & 1 \\\\\n",
    " -1 & 0\n",
    " \\end{bmatrix}}\n",
    "}_{\\textstyle A} }\n",
    "\\color{red}{\\underbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  0 & 1\n",
    " \\end{bmatrix}}\n",
    "}_{\\textstyle B}}\n",
    "\\color{red}{\\overbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  1 \\\\\n",
    "  3\n",
    " \\end{bmatrix}}\n",
    "}^{\\textstyle x}}\n",
    "\\rightarrow\n",
    "\\color{red}{\\underbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  0 & 1 \\\\\n",
    "  -1 & 0\n",
    " \\end{bmatrix}}\n",
    "}_{\\textstyle A}}\n",
    "\\color{red}{\\overbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  7 \\\\\n",
    "  3\n",
    " \\end{bmatrix}}\n",
    "}^{\\textstyle Bx}}\n",
    "\\rightarrow\n",
    "\\color{red}{\\overbrace{\n",
    " \\color{black}{\\begin{bmatrix}\n",
    "  3 \\\\\n",
    "  -7\n",
    " \\end{bmatrix}}\n",
    "}^{\\textstyle y}}\n",
    "$$\n",
    "\n",
    "我们可以观察到，对向量 $ x $ 应用变换 $ AB $ 与先对 $ x $ 应用 $ B $，然后对向量 $ Bx $ 应用 $ A $ 是相同的。\n",
    "\n",
    "因此，矩阵乘积 $ AB $ 是矩阵变换 $ A $ 和 $ B $ 的[复合函数](https://baike.baidu.com/item/%E5%A4%8D%E5%90%88%E5%87%BD%E6%95%B0/6176286)。\n",
    "这意味着先应用变换 $ B $，然后应用变换 $ A $。\n",
    "\n",
    "当我们将一个 $ n \\times m $ 矩阵 $ A $ 与一个 $ m \\times k $ 矩阵 $ B $ 相乘时，得到的矩阵乘积是一个 $ n \\times k $ 矩阵 $ AB $。\n",
    "\n",
    "因此，如果 $ A $ 和 $ B $ 是变换， $ A \\colon \\mathbb{R}^m \\to \\mathbb{R}^n $ 且 $ B \\colon \\mathbb{R}^k \\to \\mathbb{R}^m $，那么 $ AB $ 将 $ \\mathbb{R}^k $ 变换到 $ \\mathbb{R}^n $。\n",
    "\n",
    "将矩阵乘法视为映射的组合有助于我们理解为什么在矩阵乘法下，$ AB $ 通常不等于 $ BA $。\n",
    "\n",
    "（毕竟，当我们使用复合函数时，顺序通常很重要。）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31517f83",
   "metadata": {},
   "source": [
    "### 示例\n",
    "\n",
    "设 $ A $ 为顺时针旋转 $ 90^{\\circ} $ 的矩阵，即 $ \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix} $ ，设 $ B $ 为沿 x 轴的剪切矩阵，即 $ \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix} $。\n",
    "\n",
    "我们将可视化当我们应用变换 $ AB $ 时点的网格如何变化，然后将其与变换 $ BA $ 进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6638333",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def grid_composition_transform(A=np.array([[1, -1], [1, 1]]),\n",
    "                               B=np.array([[1, -1], [1, 1]])):\n",
    "    xvals = np.linspace(-4, 4, 9)\n",
    "    yvals = np.linspace(-3, 3, 7)\n",
    "    xygrid = np.column_stack([[x, y] for x in xvals for y in yvals])\n",
    "    uvgrid = B @ xygrid\n",
    "    abgrid = A @ uvgrid\n",
    "\n",
    "    colors = list(map(colorizer, xygrid[0], xygrid[1]))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    for axes in ax:\n",
    "        axes.set(xlim=(-12, 12), ylim=(-12, 12))\n",
    "        axes.set_xticks([])\n",
    "        axes.set_yticks([])\n",
    "        for spine in ['left', 'bottom']:\n",
    "            axes.spines[spine].set_position('zero')\n",
    "        for spine in ['right', 'top']:\n",
    "            axes.spines[spine].set_color('none')\n",
    "\n",
    "    # 绘制格点\n",
    "    ax[0].scatter(xygrid[0], xygrid[1], s=36, c=colors, edgecolor=\"none\")\n",
    "    ax[0].set_title(r\"点 $x_1, x_2, \\cdots, x_k$\")\n",
    "\n",
    "    # 绘制中间的格点\n",
    "    ax[1].scatter(uvgrid[0], uvgrid[1], s=36, c=colors, edgecolor=\"none\")\n",
    "    ax[1].set_title(r\"点 $Bx_1, Bx_2, \\cdots, Bx_k$\")\n",
    "\n",
    "    # 绘制变换后的格点\n",
    "    ax[2].scatter(abgrid[0], abgrid[1], s=36, c=colors, edgecolor=\"none\")\n",
    "    ax[2].set_title(r\"点 $ABx_1, ABx_2, \\cdots, ABx_k$\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9db51",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[0, 1],     # 顺时针旋转90度\n",
    "              [-1, 0]])\n",
    "B = np.array([[1, 2],     # 沿x-轴剪切\n",
    "              [0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38890a2a",
   "metadata": {},
   "source": [
    "#### 剪切后旋转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c796e4b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "grid_composition_transform(A, B)  # 变换 AB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03989409",
   "metadata": {},
   "source": [
    "#### 旋转后剪切"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb13fd0",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "grid_composition_transform(B, A)         # 变换 BA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e2f829",
   "metadata": {},
   "source": [
    "很显然，变换 $ AB $ 与变换 $ BA $ 是不同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988e309",
   "metadata": {},
   "source": [
    "## 对固定映射进行迭代\n",
    "\n",
    "在经济学（尤其是动态建模）中，我们经常对重复应用固定矩阵所产生的变换感兴趣。\n",
    "\n",
    "例如，给定一个向量 $ v $ 和一个矩阵 $ A $，我们希望可以研究以下序列：\n",
    "\n",
    "$$\n",
    "v, \\quad\n",
    "    Av, \\quad\n",
    "    AAv = A^2v, \\quad \\ldots\n",
    "$$\n",
    "\n",
    "让我们首先看一下在不同映射 $ A $ 下的迭代序列 $ (A^k v)_{k \\geq 0} $ 的例子。\n",
    "\n",
    "\n",
    "<a id='plot-series'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f53ac",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def plot_series(A, v, n):\n",
    "\n",
    "    B = np.array([[1, -1],\n",
    "                  [1, 0]])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set(xlim=(-4, 4), ylim=(-4, 4))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ['left', 'bottom']:\n",
    "        ax.spines[spine].set_position('zero')\n",
    "    for spine in ['right', 'top']:\n",
    "        ax.spines[spine].set_color('none')\n",
    "\n",
    "    θ = np.linspace(0, 2 * np.pi, 150)\n",
    "    r = 2.5\n",
    "    x = r * np.cos(θ)\n",
    "    y = r * np.sin(θ)\n",
    "    x1 = x.reshape(1, -1)\n",
    "    y1 = y.reshape(1, -1)\n",
    "    xy = np.concatenate((x1, y1), axis=0)\n",
    "\n",
    "    ellipse = B @ xy\n",
    "    ax.plot(ellipse[0, :], ellipse[1, :], color='black',\n",
    "            linestyle=(0, (5, 10)), linewidth=0.5)\n",
    "\n",
    "    #初始化轨迹容器\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, 20))\n",
    "\n",
    "    for i in range(n):\n",
    "        iteration = matrix_power(A, i) @ v\n",
    "        v1 = iteration[0]\n",
    "        v2 = iteration[1]\n",
    "        ax.scatter(v1, v2, color=colors[i])\n",
    "        if i == 0:\n",
    "            ax.text(v1+0.25, v2, f'$v$')\n",
    "        elif i == 1:\n",
    "            ax.text(v1+0.25, v2, f'$Av$')\n",
    "        elif 1 < i < 4:\n",
    "            ax.text(v1+0.25, v2, f'$A^{i}v$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4386cf",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[sqrt(3) + 1, -2],\n",
    "              [1, sqrt(3) - 1]])\n",
    "A = (1/(2*sqrt(2))) * A\n",
    "v = (-3, -3)\n",
    "n = 12\n",
    "\n",
    "plot_series(A, v, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa266c0",
   "metadata": {},
   "source": [
    "每次迭代后，向量变得更短，即更靠近原点。\n",
    "\n",
    "在这种情况下，重复将向量乘以$ A $会使向量”螺旋式地向内”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b2480",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "B = np.array([[sqrt(3) + 1, -2],\n",
    "              [1, sqrt(3) - 1]])\n",
    "B = (1/2) * B\n",
    "v = (2.5, 0)\n",
    "n = 12\n",
    "\n",
    "plot_series(B, v, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e259b0b",
   "metadata": {},
   "source": [
    "在这里，每次迭代向量不会变长或变短。\n",
    "\n",
    "在这种情况下，重复将向量乘以$ A $只会使其”围绕一个椭圆旋转”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0321a9a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "B = np.array([[sqrt(3) + 1, -2],\n",
    "              [1, sqrt(3) - 1]])\n",
    "B = (1/sqrt(2)) * B\n",
    "v = (-1, -0.25)\n",
    "n = 6\n",
    "\n",
    "plot_series(B, v, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c965f6",
   "metadata": {},
   "source": [
    "在这里，每次迭代向量趋向于变长，即离原点更远。\n",
    "\n",
    "在这种情况下，重复将向量乘以$ A $会使向量”螺旋式地向外”。\n",
    "\n",
    "因此，我们观察到序列$ (A^kv)_{k \\geq 0} $的行为取决于映射$ A $本身。\n",
    "\n",
    "现在我们讨论决定这种行为的$ A $的性质。\n",
    "\n",
    "\n",
    "<a id='la-eigenvalues'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e286aa70",
   "metadata": {},
   "source": [
    "## 特征值\n",
    "\n",
    "\n",
    "<a id='index-1'></a>\n",
    "在本节中，我们引入特征值和特征向量的概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51350625",
   "metadata": {},
   "source": [
    "### 定义\n",
    "\n",
    "设 $ A $ 为 $ n \\times n $ 的方阵。\n",
    "\n",
    "如果存在标量 $ \\lambda $ 和非零 $ n $ 维向量 $ v $ ，使得\n",
    "\n",
    "$$\n",
    "A v = \\lambda v.\n",
    "$$\n",
    "\n",
    "则我们称 $ \\lambda $ 为 $ A $的 *特征值* ，$ v $ 为相应的 *特征向量*。\n",
    "\n",
    "因此，$ A $ 的特征向量是一个非零向量 $ v $，当映射 $ A $ 应用于它时，$ v $ 仅仅是被缩放。\n",
    "\n",
    "下图显示了两个特征向量（蓝色箭头）及其在 $ A $ 下的像（红色箭头）。\n",
    "\n",
    "如预期的那样，每个 $ v $ 的像 $ Av $ 只是原始向量的缩放。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11805e94",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import eig\n",
    "\n",
    "A = [[1, 2],\n",
    "     [2, 1]]\n",
    "A = np.array(A)\n",
    "evals, evecs = eig(A)\n",
    "evecs = evecs[:, 0], evecs[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# 将坐标轴设置为通过原点\n",
    "for spine in ['left', 'bottom']:\n",
    "    ax.spines[spine].set_position('zero')\n",
    "for spine in ['right', 'top']:\n",
    "    ax.spines[spine].set_color('none')\n",
    "# ax.grid(alpha=0.4)\n",
    "\n",
    "xmin, xmax = -3, 3\n",
    "ymin, ymax = -3, 3\n",
    "ax.set(xlim=(xmin, xmax), ylim=(ymin, ymax))\n",
    "\n",
    "# 绘制每个特征向量\n",
    "for v in evecs:\n",
    "    ax.annotate('', xy=v, xytext=(0, 0),\n",
    "                arrowprops=dict(facecolor='blue',\n",
    "                shrink=0,\n",
    "                alpha=0.6,\n",
    "                width=0.5))\n",
    "\n",
    "# 绘制每个特征向量\n",
    "for v in evecs:\n",
    "    v = A @ v\n",
    "    ax.annotate('', xy=v, xytext=(0, 0),\n",
    "                arrowprops=dict(facecolor='red',\n",
    "                shrink=0,\n",
    "                alpha=0.6,\n",
    "                width=0.5))\n",
    "\n",
    "# 绘制它们经过的直线\n",
    "x = np.linspace(xmin, xmax, 3)\n",
    "for v in evecs:\n",
    "    a = v[1] / v[0]\n",
    "    ax.plot(x, a * x, 'b-', lw=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a604d7b",
   "metadata": {},
   "source": [
    "### 复数值\n",
    "\n",
    "到目前为止，我们对特征值和特征向量的定义似乎很直观。\n",
    "\n",
    "但还有一个我们尚未提到的复杂情况：\n",
    "\n",
    "在求解 $ Av = \\lambda v $ 时，\n",
    "\n",
    "- $ \\lambda $ 可以是复数，并且  \n",
    "- $ v $ 可以是一个包含 n 个复数的向量。  \n",
    "\n",
    "\n",
    "我们将在下面看到一些例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d6868",
   "metadata": {},
   "source": [
    "### 一些数学细节\n",
    "\n",
    "我们为有兴趣的读者注明一些数学细节。（其他读者可以跳到下一节。）\n",
    "\n",
    "特征值方程等价于 $ (A - \\lambda I) v = 0 $。\n",
    "\n",
    "只有当 $ A - \\lambda I $ 的列线性相关时，这个方程才有非零解 $ v $。\n",
    "\n",
    "这反过来等价于行列式为零。\n",
    "\n",
    "因此，要找到所有特征值，我们可以寻找使 $ A - \\lambda I $ 的行列式为零的 $ \\lambda $。\n",
    "\n",
    "这个问题可以表示为求解一个 $ \\lambda $ 的 n 次多项式的根。\n",
    "\n",
    "这进而意味着在复平面上存在 n 个解，尽管有些可能是重复的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c519bb8",
   "metadata": {},
   "source": [
    "### 事实\n",
    "\n",
    "关于方阵 $ A $ 的特征值，有一些很好的事实：\n",
    "\n",
    "1. $ A $ 的行列式等于其特征值的乘积  \n",
    "1. $ A $ 的迹（主对角线上元素的和）等于其特征值的和  \n",
    "1. 如果 $ A $ 是对称的，那么它的所有特征值都是实数  \n",
    "1. 如果 $ A $ 可逆，且 $ \\lambda_1, \\ldots, \\lambda_n $ 是它的特征值，那么 $ A^{-1} $ 的特征值是 $ 1/\\lambda_1, \\ldots, 1/\\lambda_n $。  \n",
    "\n",
    "\n",
    "最后一个陈述的一个推论是，当且仅当矩阵的所有特征值都非零时，该矩阵才是可逆的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696de992",
   "metadata": {},
   "source": [
    "### 计算\n",
    "\n",
    "使用 NumPy，我们可以按如下方式求解矩阵的特征值和特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774988e8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import eig\n",
    "\n",
    "A = ((1, 2),\n",
    "     (2, 1))\n",
    "\n",
    "A = np.array(A)\n",
    "evals, evecs = eig(A)\n",
    "evals  # 特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803d04b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "evecs  # 特征向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd0ece",
   "metadata": {},
   "source": [
    "请注意，`evecs` 的*列*是特征向量。\n",
    "\n",
    "由于特征向量的任何标量倍数都是具有相同特征值的特征向量（可以试着验证一下），`eig` 程序将每个特征向量的长度归一化为1。\n",
    "\n",
    "映射 $ A $ 的特征向量和特征值决定了当我们反复乘以 $ A $ 时，向量 $ v $ 如何被变换。\n",
    "\n",
    "这一点将在后面进一步讨论。\n",
    "\n",
    "\n",
    "<a id='la-neumann'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cadbc8",
   "metadata": {},
   "source": [
    "## 诺伊曼级数引理\n",
    "\n",
    "\n",
    "<a id='index-2'></a>\n",
    "在本节中，我们将介绍一个关于矩阵级数的著名结果，它在经济学中有许多应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766dcb8",
   "metadata": {},
   "source": [
    "### 标量级数\n",
    "\n",
    "以下是关于级数的一个基本结果：\n",
    "\n",
    "如果 $ a $ 是一个数，且 $ |a| < 1 $，那么\n",
    "\n",
    "\n",
    "<a id='equation-gp-sum'></a>\n",
    "$$\n",
    "\\sum_{k=0}^{\\infty} a^k =\\frac{1}{1-a} = (1 - a)^{-1} \\tag{16.1}\n",
    "$$\n",
    "\n",
    "对于一维线性方程 $ x = ax + b $，其中 x 未知，我们可以得出解 $ x^{*} $ 由以下给出：\n",
    "\n",
    "$$\n",
    "x^{*} = \\frac{b}{1-a} = \\sum_{k=0}^{\\infty} a^k b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e28546",
   "metadata": {},
   "source": [
    "### 矩阵级数\n",
    "\n",
    "这个想法在矩阵设置中也有一个推广。\n",
    "\n",
    "考虑方程组 $ x = Ax + b $，其中 $ A $ 是一个 $ n \\times n $ 的方阵，$ x $ 和 $ b $ 都是 $ \\mathbb{R}^n $ 中的列向量。\n",
    "\n",
    "使用矩阵代数，我们可以得出这个方程组的解由以下给出：\n",
    "\n",
    "\n",
    "<a id='equation-neumann-eqn'></a>\n",
    "$$\n",
    "x^{*} = (I-A)^{-1}b \\tag{16.2}\n",
    "$$\n",
    "\n",
    "什么条件保证了存在唯一的向量 $ x^{*} $ 满足方程 [(16.2)](#equation-neumann-eqn)？\n",
    "\n",
    "以下是泛函分析中的一个基本结果，它将 [(16.1)](#equation-gp-sum) 推广到多变量情况。\n",
    "\n",
    "\n",
    "<a id='neumann-series-lemma'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f6eee9",
   "metadata": {},
   "source": [
    "###  (诺伊曼级数引理)\n",
    "\n",
    "设 $ A $ 为方阵，$ A^k $ 为 $ A $ 的 $ k $ 次幂。\n",
    "设 $ r(A) $ 为 $ A $ 的**谱半径**，定义为 $ \\max_i |\\lambda_i| $，其中\n",
    "\n",
    "- $ \\{\\lambda_i\\}_i $ 是 $ A $ 的特征值集，且  \n",
    "- $ |\\lambda_i| $ 是复数 $ \\lambda_i $ 的模  \n",
    "\n",
    "\n",
    "诺伊曼定理陈述如下：如果 $ r(A) < 1 $，那么 $ I - A $ 是可逆的，且\n",
    "\n",
    "$$\n",
    "(I - A)^{-1} = \\sum_{k=0}^{\\infty} A^k\n",
    "$$\n",
    "\n",
    "我们可以在以下例子中看到诺伊曼级数引理的应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b45d3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[0.4, 0.1],\n",
    "              [0.7, 0.2]])\n",
    "\n",
    "evals, evecs = eig(A)   #求出特征值和特征向量\n",
    "\n",
    "r = max(abs(λ) for λ in evals)    # 计算谱半径\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe8143",
   "metadata": {},
   "source": [
    "获得的谱半径 $ r(A) $ 小于1。\n",
    "\n",
    "因此，我们可以应用诺伊曼级数引理来求 $ (I-A)^{-1} $。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843dbba",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "I = np.identity(2)  # 2 x 2 单位矩阵\n",
    "B = I - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d1b9d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "B_inverse = np.linalg.inv(B)  # 直接求逆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc502f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A_sum = np.zeros((2, 2))  # A 的幂级数和\n",
    "A_power = I\n",
    "for i in range(50):\n",
    "    A_sum += A_power\n",
    "    A_power = A_power @ A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a85b63f",
   "metadata": {},
   "source": [
    "让我们检查求和方法和逆序方法的结果是否相等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a0a19",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "np.allclose(A_sum, B_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae1e22",
   "metadata": {},
   "source": [
    "虽然我们在 $ k = 50 $ 时截断了无限级数，但两种方法给出了相同的结果，这体现了诺伊曼级数引理的结论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf5342",
   "metadata": {},
   "source": [
    "## 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0893c70",
   "metadata": {},
   "source": [
    "## Exercise 16.1\n",
    "\n",
    "幂迭代法是一种用于寻找可对角化矩阵最大绝对特征值的方法。\n",
    "\n",
    "该方法从一个随机向量 $ b_0 $ 开始，重复地对其应用矩阵 $ A $\n",
    "\n",
    "$$\n",
    "b_{k+1}=\\frac{A b_k}{\\left\\|A b_k\\right\\|}\n",
    "$$\n",
    "\n",
    "关于该方法的详细讨论可以在[这里](https://pythonnumericalmethods.berkeley.edu/notebooks/chapter15.02-The-Power-Method.html)找到。\n",
    "\n",
    "在这个练习中，首先实现幂迭代方法，并用它来找出最大绝对特征值及其对应的特征向量。\n",
    "\n",
    "然后可视化收敛过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5cd2a9",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 16.1](https://quantecon.github.io/lecture-intro.zh-cn/#eig1_ex1)\n",
    "\n",
    "这里有一个解决方案。\n",
    "\n",
    "我们首先研究特征向量近似值与真实特征向量之间的距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02fe63",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# 定义矩阵A\n",
    "A = np.array([[1, 0, 3],\n",
    "              [0, 2, 0],\n",
    "              [3, 0, 1]])\n",
    "\n",
    "num_iters = 20\n",
    "\n",
    "# 定义一个随机的初始向量 b\n",
    "b = np.random.rand(A.shape[1])\n",
    "\n",
    "# 获取矩阵A的主特征向量\n",
    "eigenvector = np.linalg.eig(A)[1][:, 0]\n",
    "\n",
    "errors = []\n",
    "res = []\n",
    "\n",
    "# 幂迭代循环\n",
    "for i in range(num_iters):\n",
    "    # Multiply b by A\n",
    "    b = A @ b\n",
    "    # 归一化b\n",
    "    b = b / np.linalg.norm(b)\n",
    "    # 将b添加到特征向量近似值列表中\n",
    "    res.append(b)\n",
    "    err = np.linalg.norm(np.array(b)\n",
    "                         - eigenvector)\n",
    "    errors.append(err)\n",
    "\n",
    "greatest_eigenvalue = np.dot(A @ b, b) / np.dot(b, b)\n",
    "print(f'近似的最大绝对特征值是 \\\n",
    "        {greatest_eigenvalue:.2f}')\n",
    "print('真实的特征值是', np.linalg.eig(A)[0])\n",
    "\n",
    "# 绘制每次迭代的特征向量近似值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel('次数')\n",
    "plt.ylabel('误差')\n",
    "_ = plt.plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e4a20",
   "metadata": {},
   "source": [
    "然后我们可以观察特征向量近似值的轨迹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d8c8d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# 设置3D图形和坐标轴\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 绘制特征向量\n",
    "ax.scatter(eigenvector[0],\n",
    "           eigenvector[1],\n",
    "           eigenvector[2],\n",
    "           color='r', s=80)\n",
    "\n",
    "for i, vec in enumerate(res):\n",
    "    ax.scatter(vec[0], vec[1], vec[2],\n",
    "               color='b',\n",
    "               alpha=(i+1)/(num_iters+1),\n",
    "               s=80)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "\n",
    "points = [plt.Line2D([0], [0], linestyle='none',\n",
    "                     c=i, marker='o') for i in ['r', 'b']]\n",
    "ax.legend(points, ['真正的特征向量',\n",
    "                   r'近似的特征向量 ($b_k$)'])\n",
    "ax.set_box_aspect(aspect=None, zoom=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d6671",
   "metadata": {},
   "source": [
    "## Exercise 16.2\n",
    "\n",
    "我们已经讨论了向量 $ v $ 经过矩阵 $ A $ 变换后的轨迹。\n",
    "\n",
    "考虑矩阵 $ A = \\begin{bmatrix} 1 & 2 \\\\ 1 & 1 \\end{bmatrix} $ 和向量 $ v = \\begin{bmatrix} 2 \\\\ -2 \\end{bmatrix} $。\n",
    "\n",
    "尝试计算向量 $ v $ 经过矩阵 $ A $ 变换 $ n=4 $ 次迭代后的轨迹，并绘制结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a6d66",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 16.2](https://quantecon.github.io/lecture-intro.zh-cn/#eig1_ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196eacd5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2],\n",
    "              [1, 1]])\n",
    "v = (0.4, -0.4)\n",
    "n = 11\n",
    "\n",
    "# 计算特征值和特征向量\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "\n",
    "print(f'特征值:\\n {eigenvalues}')\n",
    "print(f'特征向量:\\n {eigenvectors}')\n",
    "\n",
    "plot_series(A, v, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761d6cf",
   "metadata": {},
   "source": [
    "结果似乎收敛于矩阵 $ A $ 最大特征值对应的特征向量。\n",
    "\n",
    "让我们使用[向量场](https://baike.baidu.com/item/%E5%90%91%E9%87%8F%E5%9C%BA/9812041)来可视化矩阵 $ A $ 带来的变换。\n",
    "（这是线性代数中的一个较高级话题，如果你对数学感到足够自信和感兴趣的话，可以继续往下学习。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc4ba1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# 创建格点\n",
    "x, y = np.meshgrid(np.linspace(-5, 5, 15),\n",
    "                   np.linspace(-5, 5, 20))\n",
    "\n",
    "#将矩阵A应用于向量场中的每个点\n",
    "vec_field = np.stack([x, y])\n",
    "u, v = np.tensordot(A, vec_field, axes=1)\n",
    "\n",
    "# 绘制转换后的向量场\n",
    "c = plt.streamplot(x, y, u - x, v - y,\n",
    "                   density=1, linewidth=None, color='#A23BEC')\n",
    "c.lines.set_alpha(0.5)\n",
    "c.arrows.set_alpha(0.5)\n",
    "\n",
    "# 绘制特征向量\n",
    "origin = np.zeros((2, len(eigenvectors)))\n",
    "parameters = {'color': ['b', 'g'], 'angles': 'xy',\n",
    "              'scale_units': 'xy', 'scale': 0.1, 'width': 0.01}\n",
    "plt.quiver(*origin, eigenvectors[0],\n",
    "           eigenvectors[1], **parameters)\n",
    "plt.quiver(*origin, - eigenvectors[0],\n",
    "           - eigenvectors[1], **parameters)\n",
    "\n",
    "colors = ['b', 'g']\n",
    "lines = [Line2D([0], [0], color=c, linewidth=3) for c in colors]\n",
    "labels = [\"2.4 特征空间\", \"0.4 特征空间\"]\n",
    "plt.legend(lines, labels, loc='center left',\n",
    "           bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf52729",
   "metadata": {},
   "source": [
    "请注意，向量场收敛于$ A $的最大特征值对应的特征向量，并从$ A $的最小特征值对应的特征向量发散。\n",
    "\n",
    "实际上，特征向量也是矩阵$ A $拉伸或压缩空间的方向。\n",
    "\n",
    "具体来说，最大特征值对应的特征向量是矩阵$ A $最大程度拉伸空间的方向。\n",
    "\n",
    "我们将在接下来的练习中看到更多有趣的例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e183e1c",
   "metadata": {},
   "source": [
    "## Exercise 16.3\n",
    "\n",
    "[之前](#plot-series)，我们展示了向量$ v $被三种不同矩阵$ A $变换后的轨迹。\n",
    "\n",
    "使用前面练习中的可视化来解释向量$ v $被这三种不同矩阵$ A $变换后的轨迹。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631ab91",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 16.3](https://quantecon.github.io/lecture-intro.zh-cn/#eig1_ex3)\n",
    "\n",
    "以下是其中一种解法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69088e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "A = np.array([[sqrt(3) + 1, -2],\n",
    "              [1, sqrt(3) - 1]])\n",
    "A = (1/(2*sqrt(2))) * A\n",
    "\n",
    "B = np.array([[sqrt(3) + 1, -2],\n",
    "              [1, sqrt(3) - 1]])\n",
    "B = (1/2) * B\n",
    "\n",
    "C = np.array([[sqrt(3) + 1, -2],\n",
    "              [1, sqrt(3) - 1]])\n",
    "C = (1/sqrt(2)) * C\n",
    "\n",
    "examples = [A, B, C]\n",
    "\n",
    "for i, example in enumerate(examples):\n",
    "    M = example\n",
    "\n",
    "    # 计算特征向量和特征值\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(M)\n",
    "    print(f'实例 {i+1}:\\n')\n",
    "    print(f'特征值:\\n {eigenvalues}')\n",
    "    print(f'特征向量:\\n {eigenvectors}\\n')\n",
    "\n",
    "    eigenvalues_real = eigenvalues.real\n",
    "    eigenvectors_real = eigenvectors.real\n",
    "\n",
    "    # 创建格点\n",
    "    x, y = np.meshgrid(np.linspace(-20, 20, 15),\n",
    "                       np.linspace(-20, 20, 20))\n",
    "\n",
    "    # 将矩阵A应用于向量场中的每个点\n",
    "    vec_field = np.stack([x, y])\n",
    "    u, v = np.tensordot(M, vec_field, axes=1)\n",
    "\n",
    "    # 绘制转换后的向量场\n",
    "    c = ax[i].streamplot(x, y, u - x, v - y, density=1,\n",
    "                         linewidth=None, color='#A23BEC')\n",
    "    c.lines.set_alpha(0.5)\n",
    "    c.arrows.set_alpha(0.5)\n",
    "\n",
    "    # 绘制特征向量\n",
    "    parameters = {'color': ['b', 'g'], 'angles': 'xy',\n",
    "                  'scale_units': 'xy', 'scale': 1,\n",
    "                  'width': 0.01, 'alpha': 0.5}\n",
    "    origin = np.zeros((2, len(eigenvectors)))\n",
    "    ax[i].quiver(*origin, eigenvectors_real[0],\n",
    "                 eigenvectors_real[1], **parameters)\n",
    "    ax[i].quiver(*origin,\n",
    "                 - eigenvectors_real[0],\n",
    "                 - eigenvectors_real[1],\n",
    "                 **parameters)\n",
    "\n",
    "    ax[i].set_xlabel(\"x-axis\")\n",
    "    ax[i].set_ylabel(\"y-axis\")\n",
    "    ax[i].grid()\n",
    "    ax[i].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b96082",
   "metadata": {},
   "source": [
    "这些向量场解释了为什么我们之前观察到向量$ v $被矩阵$ A $反复相乘后的轨迹。\n",
    "\n",
    "这里展示的模式是因为我们有复数特征值和特征向量。\n",
    "\n",
    "我们可以使用从[stackoverflow](https://stackoverflow.com/questions/22867620/putting-arrowheads-on-vectors-in-a-3d-plot)获取的`Arrow3D`类来为其中一个矩阵绘制复平面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c53356",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        super().__init__((0, 0), (0, 0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def do_3d_projection(self):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d,\n",
    "                                           self.axes.M)\n",
    "        self.set_positions((0.1*xs[0], 0.1*ys[0]),\n",
    "                           (0.1*xs[1], 0.1*ys[1]))\n",
    "\n",
    "        return np.min(zs)\n",
    "\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "\n",
    "#为向量场创建网格\n",
    "x, y = np.meshgrid(np.linspace(-2, 2, 15),\n",
    "                   np.linspace(-2, 2, 15))\n",
    "\n",
    "# 计算向量场（实部和虚部）\n",
    "u_real = A[0][0] * x + A[0][1] * y\n",
    "v_real = A[1][0] * x + A[1][1] * y\n",
    "u_imag = np.zeros_like(x)\n",
    "v_imag = np.zeros_like(y)\n",
    "\n",
    "# 创建3D图像\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "vlength = np.linalg.norm(eigenvectors)\n",
    "ax.quiver(x, y, u_imag, u_real-x, v_real-y, v_imag-u_imag,\n",
    "          colors='b', alpha=0.3, length=.2,\n",
    "          arrow_length_ratio=0.01)\n",
    "\n",
    "arrow_prop_dict = dict(mutation_scale=5,\n",
    "                       arrowstyle='-|>', shrinkA=0, shrinkB=0)\n",
    "\n",
    "# 绘制3D特征向量\n",
    "for c, i in zip(['b', 'g'], [0, 1]):\n",
    "    a = Arrow3D([0, eigenvectors[0][i].real],\n",
    "                [0, eigenvectors[1][i].real],\n",
    "                [0, eigenvectors[1][i].imag],\n",
    "                color=c, **arrow_prop_dict)\n",
    "    ax.add_artist(a)\n",
    "\n",
    "# 设置坐标轴标签和标题\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('Im')\n",
    "ax.set_box_aspect(aspect=None, zoom=0.8)\n",
    "\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "date": 1743998656.0859888,
  "filename": "eigen_I.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "特征值和特征向量"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}